data data3412;
input id Y X0 X1 X2 X3 X4;
X0_X1 = X0*X1;
X0_X2 = X0*X2;
X0_X3 = X0*X3;
X0_X4 = X0*X4;
datalines;
1 4.111556442	1	0.288844676	0.551189061	0.161896774	0.464226434
2 -0.046433933	1	0.258207629	0.171677241	-0.012428617	-0.090557033
3 6.592970187	1	0.925088256	1.10644596	1.025293329	0.94738729
4 0.551724285	1	-0.764326075	-0.642565994	-0.870956404	-0.870664616
5 -1.066575171	1	-0.746979995	-0.709253064	-0.577117407	-0.914030807
6 -7.217089834	1	-1.15787474	-1.333440851	-0.936631869	-1.282142447
7 -3.12354572	1	-1.111645964	-1.170923053	-1.190706822	-0.970881623
8 -8.264967706	1	-2.634843264	-2.479657133	-2.497078797	-2.600453135
9 4.346496683	1	1.112121701	1.156827383	1.009133116	1.271631433
10 -0.078527286	1	-0.106430795	-0.082383071	-0.236290284	0.229574235
11 2.999486277	1	0.378361155	0.478186444	0.553436224	0.337159394
12 4.13818178	1	0.272605409	0.393262056	0.109036017	0.528058423
13 0.244529695	1	-0.975709113	-0.808624594	-0.617408609	-0.675202514
14 -0.602132183	1	-0.523205176	-0.525569041	-0.345247836	-0.371979468
15 -0.484701443	1	-0.686434674	-0.558205637	-0.475070317	-0.566710731
16 -2.286421138	1	-0.237957668	-0.219158838	-0.358543368	-0.064195868
17 11.26972242	1	1.611409846	1.65462475	1.72004828	1.676876533
18 3.76616695	1	0.847370171	0.862773402	0.514189701	0.741922852
19 -0.299651106	1	-0.478767373	-0.352658141	-0.453076433	0.096557212
20 -4.615852662	1	-0.719583364	-0.644118522	-0.762190991	-1.019047017
21 1.864043193	1	0.043520657	0.053868043	0.073296906	0.038080493
22 2.780508042	1	-0.358215673	-0.265532979	-0.316074971	-0.444815306
23 3.356095656	1	0.140082503	0.162267634	-0.07253734	0.299526244
24 -0.162203087	1	-0.307139087	-0.449478559	-0.196551829	-0.177492243
25 -5.432058195	1	-1.451942831	-1.097588048	-1.306867377	-1.287097371
26 5.417305368	1	1.115529637	1.194595533	1.081526205	1.035758701
27 -7.198726531	1	-1.224848244	-1.4391049	-1.506776594	-1.433005696
28 -4.496462334	1	-1.137939019	-1.170471687	-0.882453067	-1.139215343
29 7.313662973	1	1.744019059	1.41478618	1.442762737	1.754436983
30 2.944099257	1	1.059191999	0.846431721	0.947736255	0.683153124
31 -0.579496008	1	-1.474252163	-1.4105792	-1.281685062	-1.164104565
32 -1.136717071	1	0.488973004	0.29264618	0.358676723	0.358222767
33 0.981877222	1	0.328537329	0.518450086	0.232763931	0.343536402
34 -0.438374016	1	0.447736479	0.358198766	0.543426597	0.437076732
35 2.589087376	1	-0.990787935	-0.974759947	-1.407321886	-1.243021365
36 4.47988869	1	0.645280822	0.643251507	0.759216391	0.63011857
37 -0.784614873	1	-0.085864456	-0.101372532	0.05551263	0.038546146
38 4.022190386	1	0.80808265	0.874170958	1.014674004	1.122727036
39 1.139536846	1	-0.241700599	-0.177586041	-0.329375489	-0.28055039
40 3.367967343	1	-0.103934604	-0.316565609	-0.307132412	-0.152641048
41 -6.987877048	1	-1.321713655	-1.393305442	-1.520570818	-1.316208986
42 -1.921390689	1	-0.241063765	-0.330649011	-0.161087088	-0.486593633
43 3.23813253	1	-0.192107855	-0.311583446	-0.350505922	-0.282439746
44 -7.851977462	1	-1.192501279	-1.116277373	-1.185894334	-1.081211623
45 -7.902669259	1	-1.672703682	-1.722150335	-1.542248327	-1.684584348
46 -3.076085251	1	-1.029893728	-1.545070441	-1.129829732	-1.396366578
47 10.13021919	1	2.023994241	2.025440152	2.053191944	1.733129086
48 -1.094386731	1	-0.548940491	-0.730530616	-0.333318131	-0.336520374
49 5.432919646	1	1.297006727	1.482581602	1.290433584	1.14801291
50 -7.152469998	1	-2.283142418	-2.074296601	-2.276497318	-2.094061069
51 0.736572363	0	0.274769607	0.226505698	0.467319584	0.145072144
52 0.486172248	0	0.497982807	0.272479771	0.197423299	0.125378083
53 -3.102568421	0	0.761450815	0.641618588	0.74983328	0.655582975
54 -1.482114043	0	-0.271789637	-0.226617109	-0.114573706	-0.171090134
55 5.678008298	0	-1.058809082	-0.822451237	-1.083310977	-0.896518866
56 -2.402147853	0	0.430642328	0.529015494	0.329046545	0.250378401
57 -2.596125321	0	-0.038695514	-0.096125823	-0.169652434	0.113055648
58 -5.020727329	0	1.0880829	1.021278101	0.935896337	0.946475368
59 5.131309903	0	-0.693669847	-0.545664663	-0.598617206	-0.451188027
60 5.223034847	0	-0.871610435	-0.93076764	-0.89392854	-0.671177309
61 -0.797108142	0	0.394871321	0.277927367	0.526689233	0.645654061
62 3.704274395	0	-0.676754207	-0.479492272	-0.449570724	-0.553664687
63 13.78726338	0	-1.859097708	-1.76188461	-1.905497318	-1.841810601
64 -3.489149358	0	0.589537389	0.514243102	0.547462706	0.774486268
65 2.180430233	0	0.070461287	-0.14002836	0.302944407	0.229927666
66 -4.885054205	0	0.732543444	0.89772698	1.216019891	0.96345766
67 4.779451331	0	-0.511087887	-0.502561576	-0.501231611	-0.455422413
68 0.703562939	0	-0.038332379	-0.188809865	-0.235319497	-0.131891409
69 -4.307938614	0	0.106094841	0.280716032	-0.024642686	0.071478253
70 -4.430837351	0	0.475945872	0.738328336	0.588761009	0.568379058
71 -8.24260755	0	1.438312785	1.623039217	1.524062714	1.650792624
72 1.474325168	0	-0.46568259	-0.329367833	-0.55758837	-0.643397198
73 7.532050351	0	-0.450651296	-0.566012829	-0.863321919	-0.719312602
74 -3.242549789	0	0.427788062	0.41447208	0.228742357	0.122039808
75 6.53460741	0	-0.564139713	-0.893950313	-0.584432592	-0.821759709
76 -16.65701988	0	2.332325841	2.194118375	2.147999903	2.207134969
77 1.751169356	0	0.14451905	0.014886021	0.299947684	0.0284784
78 0.027012239	0	0.573822556	0.609594585	0.483774209	0.600825877
79 -2.484343179	0	0.826307927	0.734071688	1.127834403	0.809034318
80 0.802682915	0	-0.345335264	-0.544168695	-0.720581033	-0.596818203
81 -0.374835355	0	0.347248699	0.529980029	0.502169167	0.481240365
82 -0.722994344	0	0.004929161	-0.045414476	-0.011014781	-0.186736853
83 -6.838734179	0	0.038045548	0.449801796	0.125124915	0.147200457
84 -3.865341518	0	1.408310362	1.000166125	1.176805197	1.340293708
85 4.915281638	0	-1.673570075	-1.943076164	-1.582651012	-1.825752314
86 -3.384083518	0	0.007405577	-0.031588289	-0.03195198	-0.195638731
87 -2.284815673	0	0.436573469	0.436490517	0.553804997	0.63532826
88 -2.363465948	0	1.00026305	0.642298395	0.758454945	0.799952101
89 -6.750927464	0	1.152595518	1.242014895	1.019297362	1.069061997
90 2.395878617	0	0.41658397	0.682792266	0.295008816	0.645772568
91 1.073981309	0	-0.32652785	-0.129137499	-0.073284523	-0.114754299
92 -5.136755595	0	0.60530321	0.737705005	0.710006193	0.709532352
93 10.91676791	0	-1.63161481	-1.766756714	-1.766351153	-1.462445047
94 1.27108707	0	0.026743787	-0.13553267	-0.080774459	-0.146122871
95 -0.79067508	0	-0.593398294	-0.592961366	-0.800606123	-0.599848682
96 -6.634253132	0	1.498369524	1.413607565	1.569381666	1.585640429
97 3.710479542	0	-0.268677135	-0.7670269	-0.591034498	-0.55487087
98 -8.069290882	0	1.596979204	1.509418207	1.514159124	1.427285308
99 5.482622434	0	-1.33891656	-1.592854061	-1.396155738	-1.729835845
100 0.997375497	0	-0.030890732	0.000697923	0.161970226	-0.146993732
;

*print the data;
proc print data = data3412;
run;

*sort the data to make it possible to make boxplots;
proc sort data = data3412;
by X0;
run;

*boxplots to see if there are any outliers within the data;
proc boxplot data = data3412;
plot (Y X1 X2 X3 X4) * X0 / boxstyle = schematic;
run;

*There are absolutely no outliers for any variables in group X0 = 1. However there is one outlier in X0 = 0 by X1 and two outliers in X0 = 0 by Y;

*Let's look at the scatterplots to see correlation, shape of graph, and to just get a view of what could be significant in the model. We're not 
including the categorical variable X0;
proc corr data = data3412 plots = matrix(histogram);
var Y X1 X2 X3 X4;
run;

*All of the independent variables are highly correlated with each other. A terrible case of collinearity. All of the variables are extremely
weakly correlated with Y;

*Testing for interaction;
proc plot data = data3412;
plot Y * (X1 X2 X3 X4) = X0;
run;

*I will be assuming that there are interactions between X0 and every other independent variable;
proc reg data = data3412 plots = none;
model Y = X0 X1 X2 X3 X4 X0_X1 X0_X2 X0_X3 X0_X4 / vif collinoint;
run;

*After running the full model, every single variable, including the interactions are collinear with other variables, most likely all of them,
EXCEPT for gender, which is the only one that has a VIF < 10. The proportions of variance are good however, as well as the condition indexes. 
This looks like it might be either JUST gender, or gender and one other term: a single variable or an interaction term. R^2 is 0.7996 and Adjrsq 
is 0.7796; 

*Since we have interaction terms in the model, we can't use Backwards, Forwards, or Stepwise, so we'll go straight into the R^2, Cp, Adjrsq, and 
MaxR;

*Actually, we'll start with backwards, forwards, and stepwise. From there, we'll decide if interaction
terms are even needed in the model

*Backwards;
proc reg data = data3412 plots = none;
model Y = X0 X1 X2 X3 X4 / selection = b slstay = 0.10;
run;

*With backwards, none of the variables are significant enough to be in the model. Most depressing.

*Forwards;
proc reg data = data3412 plots = none;
model Y = X0 X1 X2 X3 X4 / selection = F slentry = 0.05;
run;

*With forwards, none of the variables are significant enough to be in the model. Again, this is sad.

*Stepwise;
proc reg data = data3412 plots = none;
model Y = X0 X1 X2 X3 X4 / selection = stepwise slstay = 0.05 slentry = 0.05;
run;

*Surprise surprise, none of the variables, on their own, were significant enough to be in the model. Looks
like we'll have to include interactions as well...

proc reg data = data3412 plots = none;
model Y = X0 X1 X2 X3 X4 X0_X1 X0_X2 X0_X3 X0_X4 / selection = rsquare;
run;

*The transition in R^2 from the best one-variable model to the best two-variable model increased by nearly 46%, which is heavily significant. From
two-variable to three and so on, the R^2 does not change significantly, so it's safe to assume that a two or three variable model will work the best.
Actually, since there are interaction terms, any of the terms that make the interaction have to be included in the model. This can include: 

1) X0 X1 X0_X1
2) X0 X2 X0_X2
3) X0 X3 X0_X3
4) X0 X4 X0_X4
5) X0 X1 X2 X0_X1 X0_X2
6) X0 X1 X3 X0_X1 X0_X3
7) X0 X1 X4 X0_X1 X0_X4
8) X0 X2 X3 X0_X2 X0_X3
9) X0 X2 X4 X0_X2 X0_X4
10) X0 X3 X4 X0_X3 X0_X4

I won't go past 5 variables in the model since the R^2 don't really change significantly

And out of these:

1) X0 X2 X0_X2 with R^2 of 0.7943 
2) X0 X1 X0_X1 with R^2 of 0.7703
3) X0 X4 X0_X4 with R^2 of 0.7610
4) X0 X3 X0_X3 with R^2 of 0.7578
5) X0 X1 X2 X0_X1 X0_X2 with R^2 of 0.7947
6) X0 X1 X3 X0_X1 X0_X3 with R^2 of 0.7729
7) X0 X1 X4 X0_X1 X0_X4 with R^2 of 0.7758
8) X0 X2 X3 X0_X2 X0_X3 with R^2 of 0.7945
9) X0 X2 X4 X0_X2 X0_X4 with R^2 of 0.7965
10) X0 X3 X4 X0_X3 X0_X4 with R^2 of 0.7697

All of them! They all have fairly close and good R^2, so we might as well test them.

Let's look at Cp just in case;

proc reg data = data3412 plots = none;
model Y = X0 X1 X2 X3 X4 X0_X1 X0_X2 X0_X3 X0_X4 / selection = cp;
run;

*X0 X2 X0_X2 has a Cp of 0.4115 which is awful
*And every other possible model is absolutely TERRIBLE with Cp. As a matter of fact, all of them do. So I won't be considering the Cp at all;

proc reg data = data3412 plots = none;
model Y = X0 X1 X2 X3 X4 X0_X1 X0_X2 X0_X3 X0_X4 / selection = adjrsq;
run;

*Adjusted R^2:

1) X0 X2 X0_X2: Adjrsq - 0.7878 R^2 - 0.7964
2) X0 X2 X3 X0_X2 X0_X3: Adjrsq - 0.7836 R^2 - 0.7945
3) X0 X1 X2 X0_X1 X0_X2: Adjrsq - 0.7838 R^2 - 0.7947

*We can even try running a Maxr just to see what the "best" variable models are;
proc reg data = data3412 plots = none;
model Y = X0 X1 X2 x3 X4 X0_X1 X0_X2 X0_X3 X0_X4 / selection = maxr;
run;

*The "best" 5 variable model does not include the interactions with X4
*The "best 3 variable model is X0 X2 X0_X2, which is looking very delectable to use as my model;

*Let's look at minr?;

proc reg data = data3412 plots = none;
model Y = X0 X1 X2 X3 X4 X0_X1 X0_X2 X0_X3 X0_X4 / selection = minr;
run; 

*Nothing significantly different;

*So now to compare the models I feel like are worth looking at to find a good fit!;

proc reg data = data3412 plots = none outest = result;
model Y = X0 X2 X0_X2 / mse press rsquare adjrsq aic bic sbc;
model Y = X0 X2 X3 X0_X2 X0_X3 / mse press rsquare adjrsq aic bic sbc;
model Y = X0 X1 X2 X0_X1 X0_X2 / mse press rsquare adjrsq aic bic sbc;
run;

proc print data = result;
var _model_  _DEPVAR_  Intercept X0 X1 X2 X3 X0_X1 X0_X2 X0_X3;
run;

proc print data = result;
var _MODEL_ _TYPE_ _DEPVAR_ _RMSE_ _PRESS_ _IN_ _P_ _EDF_ _MSE_ _RSQ_ _ADJRSQ_ _AIC_ _BIC_ _SBC_;
run;

*X0 X2 X0_X2 seems to be the best model to use!

*We can do a test to see if X0_X2 is significant at all as an interaction term in the model;

proc reg data = data3412;
model Y = X0 X2 X0_X2;
test X0_X2 = 0;
run;

*Let's run some diagnostics;

proc reg data = data3412;
model Y = X0 X2 X0_X2 / r influence vif;
run;

*Let's first remove observation number 35 and see what happens;
proc reg data = data3412; where id not in (13, 26, 35);
model Y = X0 X2 X0_X2 / r influence vif;
run;

*Looks like removing all of the outliers that went past the cook's D threshold improved the R^2 by 3%,
which is pretty good;

*Since we have an actual model without all of that collinearity mumbo jumbo, let's look at the correlation
between X2 and X0_X2;

proc corr data = data3412 plot = matrix(histogram);
var Y X2 X0_X2;
run;

*Looking at this, there is collinearity between X2 and X0_X2, and the interaction term seems to moderately
predict Y, so we can keep it in the model. Since it IS in the model, the other two variables that make up
the interaction have to be in the model as well. Ergo, no significant changes. Also, take note of the VIFs
in the model creation. They are WAY below 10. Great! No significant collinearity;

*Look at the residuals vs Y-hat and residuals vs predictor variables;

proc reg data = data3412; where id not in (13, 26, 35);
model Y = X0 X2 X0_X2;
run;

*The spread is random and not showing any patterns, so a linear model is appropriate;

*Test for normality;
proc univariate data = data3412 plot normal; where id not in (13, 26, 35);
var X0 X2 X0_X2;
run;

*H0: Data is normally distributed;
*Ha: Data is not normally distributed;
*At the 0.05 significance level, the p-value is greater than the alpha (0.05), so we fail to reject the
null hypothesis. We say that there is no evidence to suggest non-normality;

*Test for constant variance;
proc reg data = data3412; where id not in (13, 26, 35);
model Y = X0 X2 X0_X2 / spec;
run;

proc reg data = data3412; 
where id not in (13, 26, 35);
model Y = X0 X2 X0_X2;
run;

*H0: Variances are equal
*Ha: Variances are not equal
*At the 0.05 significance level, the p-value for the Chi-squared test is greater than the alpha (0.05), so 
we fail to reject the null hypothesis. There is no evidence to suggest that the variances are not equal;

*Conclusion:

After everything, all of the Exploratory Data Analysis, where there were a few outiers in the data, where
there was multicollinearity amongst the independent variables and how separately, the independent 
variables did not correlate at all with the dependent variable, and how X0 interacts with all of the other 
independent variables, I used avs methods to see if there were any possible combinations of variables w/o
interactions. They resulted in no variables in the model. I used R^2 and Adjusted R^2 and got 3 models
that were worth inspecting:

1) X0 X2 X0_X2
2) X0 X2 X3 X0_X2 X0_X3
3) X0 X1 X2 X0_X1 X0_X2

After looking at all of the selection criteria, the model with the lowerst PRESS, AIC, BIC, and SBC is
the 3 term model with an interaction: X0 X2 X0_X2.

All of the independent variables are significant at the %5 level, as well as the model being significant.

Next, I performed a regression diagnostics. I removed 3 extreme outliers which were WAY past the Cook's 
Distance, and it improved the model by 2%, which is pretty good. I looked at the possible collinearity 
between X2 and X0_X2, and it isn't as strong as the collinearity among each independent variable was, but
it is still strong. In the case of which variable to keep, I would keep X0_X2, but for there to be an 
interaction term in the model, the terms that make it up need to be in the model as well, regardless of 
their significance. Looking at the plots of the residuals vs the predicted value and the residuals vs the
independent variables, the plot points are random and not following a pattern, suggesting a linear model
is appropriate. After doing a test for normality, since the dataset is large, we use the Smirnov p-value, 
which was greater than the alpha (0.05), we conluded that there is no evidence to suggest non-normality.
After doing a test for constant variance, we conclude that there is no evidence to suggest that there
is not equality amongst variances. 

After all of this, I can conclude that the best model for prediciting Y, using this data, is:

Y = 0.11079 + 0.81783*X0 - 5.34477*X2 + 9.54076*X0_X2;






